{"chunk_id": "345c7f5869d7:0", "document_id": "345c7f5869d7", "text": "RAG Overview\n------------\nRetrieval-Augmented Generation (RAG) combines a retriever and a generator so large language models can answer questions using private or up-to-date context. A dense vector store such as Chroma or FAISS stores document chunks, and a retriever selects the top-k chunks to ground the LLM response. This pattern improves factual accuracy and allows auditors to trace each statement back to its source document ID and page number.", "section": null, "page_number": null, "chunk_index": 0, "token_count": 69, "metadata": {"source": "data/uploads/rag_sample.txt", "source_name": "rag_sample.txt"}}
{"chunk_id": "345c7f5869d7:1", "document_id": "345c7f5869d7", "text": "Key Benefits\n------------\n1. Fresh Knowledge: By indexing PDFs, DOCX, and TXT files, teams can update the vector store whenever new policies or specs arrive without retraining an LLM.\n2. Compliance: RAG prompts can require the model to cite chunk IDs, helping reviewers verify claims against the originating document.\n3. Cost Control: Hybrid retrieval (dense + sparse/BM25) narrows the context passed to the LLM, reducing token usage while keeping recall high.", "section": null, "page_number": null, "chunk_index": 1, "token_count": 71, "metadata": {"source": "data/uploads/rag_sample.txt", "source_name": "rag_sample.txt"}}
{"chunk_id": "345c7f5869d7:2", "document_id": "345c7f5869d7", "text": "Implementation Notes\n--------------------\n- Chunking: Use a RecursiveCharacterTextSplitter with ~600 token chunks and 120 token overlap to keep passages coherent.\n- Embeddings: Open-source models like `nomic-ai/nomic-embed-text-v1.5` work well for general knowledge bases and can run locally.\n- Observability: Log each query, retrieved chunk IDs, latency (p50/p95), and token counts to detect regressions.", "section": null, "page_number": null, "chunk_index": 2, "token_count": 52, "metadata": {"source": "data/uploads/rag_sample.txt", "source_name": "rag_sample.txt"}}
{"chunk_id": "345c7f5869d7:3", "document_id": "345c7f5869d7", "text": "Evaluation Checklist\n--------------------\n- Functional tests should include questions that require synthesizing two documents and ones that should return \"I don't know\" when evidence is missing.\n- Performance tests should target p95 end-to-end latency below 2.5 seconds with at least 20 concurrent queries.", "section": null, "page_number": null, "chunk_index": 3, "token_count": 43, "metadata": {"source": "data/uploads/rag_sample.txt", "source_name": "rag_sample.txt"}}

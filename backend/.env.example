# Core application settings
RAG_ENVIRONMENT=local
RAG_DEBUG=false

# Model provider configuration
# Default: OpenAI (requires OPENAI_API_KEY)
RAG_MODEL__LLM_PROVIDER=openai
RAG_MODEL__LLM_MODEL=gpt-4o-mini
OPENAI_API_KEY=
# RAG_MODEL__OPENAI_API_BASE=https://api.openai.com/v1

# To use a local Ollama runtime instead, uncomment the following and set provider accordingly
# RAG_MODEL__LLM_PROVIDER=ollama
# RAG_MODEL__LLM_MODEL=mistral-7b-instruct:latest
# RAG_MODEL__LLM_BASE_URL=http://localhost:11434

# Embedding model
RAG_MODEL__EMBED_MODEL=nomic-ai/nomic-embed-text-v1.5

# Observability
RAG_OBSERVABILITY__ENABLE_TRACING=true
RAG_OBSERVABILITY__OTLP_ENDPOINT=http://localhost:4318

# LangChain caching
RAG_CACHE__ENABLED=true
RAG_CACHE__PATH=data/cache/lc_cache.db
